{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用已有的关联做推荐\n",
    "\n",
    "一种思路是使用已有的关联做推荐,比如亚马逊推荐商品,网飞推荐电视剧,他们已经有一些用户对商品的行为数据,比如点击行为,收藏行为,购买行为.对这些行为加权处理为一个范围内的数值,就可以认为这是一个用户对一个物品的关联.\n",
    "\n",
    "处理这种已有关联的数据我们有两种方式:\n",
    "\n",
    "1. 协同过滤\n",
    "2. 基于矩阵分解的算法\n",
    "\n",
    "要使用已有的关联做推荐,首先我们可以建立一个行为物品,列为用户的关系矩阵,以下这个例子来自于集体智慧编程.是一个向用户推荐电影的例子.用户评分范围为1到5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics={'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5,\n",
    " 'Just My Luck': 3.0, 'Superman Returns': 3.5, 'You, Me and Dupree': 2.5, \n",
    " 'The Night Listener': 3.0},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5, \n",
    " 'Just My Luck': 1.5, 'Superman Returns': 5.0, 'The Night Listener': 3.0, \n",
    " 'You, Me and Dupree': 3.5}, \n",
    "'Michael Phillips': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.0,\n",
    " 'Superman Returns': 3.5, 'The Night Listener': 4.0},\n",
    "'Claudia Puig': {'Snakes on a Plane': 3.5, 'Just My Luck': 3.0,\n",
    " 'The Night Listener': 4.5, 'Superman Returns': 4.0, \n",
    " 'You, Me and Dupree': 2.5},\n",
    "'Mick LaSalle': {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0, \n",
    " 'Just My Luck': 2.0, 'Superman Returns': 3.0, 'The Night Listener': 3.0,\n",
    " 'You, Me and Dupree': 2.0}, \n",
    "'Jack Matthews': {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0,\n",
    " 'The Night Listener': 3.0, 'Superman Returns': 5.0, 'You, Me and Dupree': 3.5},\n",
    "'Toby': {'Snakes on a Plane':4.5,'You, Me and Dupree':1.0,'Superman Returns':4.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Just My Luck</th>\n",
       "      <th>Lady in the Water</th>\n",
       "      <th>Snakes on a Plane</th>\n",
       "      <th>Superman Returns</th>\n",
       "      <th>The Night Listener</th>\n",
       "      <th>You, Me and Dupree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lisa Rose</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene Seymour</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Phillips</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claudia Puig</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mick LaSalle</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jack Matthews</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toby</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Just My Luck  Lady in the Water  Snakes on a Plane  \\\n",
       "Lisa Rose                  3.0                2.5                3.5   \n",
       "Gene Seymour               1.5                3.0                3.5   \n",
       "Michael Phillips           NaN                2.5                3.0   \n",
       "Claudia Puig               3.0                NaN                3.5   \n",
       "Mick LaSalle               2.0                3.0                4.0   \n",
       "Jack Matthews              NaN                3.0                4.0   \n",
       "Toby                       NaN                NaN                4.5   \n",
       "\n",
       "                  Superman Returns  The Night Listener  You, Me and Dupree  \n",
       "Lisa Rose                      3.5                 3.0                 2.5  \n",
       "Gene Seymour                   5.0                 3.0                 3.5  \n",
       "Michael Phillips               3.5                 4.0                 NaN  \n",
       "Claudia Puig                   4.0                 4.5                 2.5  \n",
       "Mick LaSalle                   3.0                 3.0                 2.0  \n",
       "Jack Matthews                  5.0                 3.0                 3.5  \n",
       "Toby                           4.0                 NaN                 1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rela_matrix = pd.DataFrame(critics).T\n",
    "rela_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这张表相当的\"理论\",真实情况是关系矩阵会比上面这个例子稀疏很多,全中国的人又多少?淘宝上的商品有多少?每个人又能接触多少的商品呢?不过暂且用这个例子来讲解使用已有的关联做推荐的方法也是够的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 协同过滤\n",
    "\n",
    "协同过滤的基本假设有两个\n",
    "\n",
    "1. 相似用户喜欢同一个商品(user-base)/相似商品会被同一个用户喜欢(item-base)\n",
    "2. 用户的喜好不随时间变化\n",
    "3. 用户不会改变,物品也不会改变\n",
    "\n",
    "\n",
    "\n",
    "我们以user-base的协同过滤为例讲下大致原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估相似度\n",
    "\n",
    "基本假设就是相似用户会喜欢同一个商品(user-base),因此我们需要先计算用户间的相似度.,如何计算相似呢?我们可以使用多种度量,常见的有\n",
    "\n",
    "+ 欧式距离\n",
    "\n",
    "$$ d = \\sqrt{\\sum\\limits_{i=1}^n (x_i - y_i)^2} $$\n",
    "\n",
    "+ 皮尔逊相关系数\n",
    "\n",
    "+ cosine相似度\n",
    "\n",
    "等,这边使用皮尔逊相关系数作为例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = rela_matrix.T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lisa Rose</th>\n",
       "      <th>Gene Seymour</th>\n",
       "      <th>Michael Phillips</th>\n",
       "      <th>Claudia Puig</th>\n",
       "      <th>Mick LaSalle</th>\n",
       "      <th>Jack Matthews</th>\n",
       "      <th>Toby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lisa Rose</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396059</td>\n",
       "      <td>0.404520</td>\n",
       "      <td>0.566947</td>\n",
       "      <td>0.594089</td>\n",
       "      <td>0.747018</td>\n",
       "      <td>0.991241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene Seymour</th>\n",
       "      <td>0.396059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204598</td>\n",
       "      <td>0.314970</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.963796</td>\n",
       "      <td>0.381246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Phillips</th>\n",
       "      <td>0.404520</td>\n",
       "      <td>0.204598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.258199</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claudia Puig</th>\n",
       "      <td>0.566947</td>\n",
       "      <td>0.314970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.566947</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.893405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mick LaSalle</th>\n",
       "      <td>0.594089</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>-0.258199</td>\n",
       "      <td>0.566947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>0.924473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jack Matthews</th>\n",
       "      <td>0.747018</td>\n",
       "      <td>0.963796</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.662849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toby</th>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.381246</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.893405</td>\n",
       "      <td>0.924473</td>\n",
       "      <td>0.662849</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Lisa Rose  Gene Seymour  Michael Phillips  Claudia Puig  \\\n",
       "Lisa Rose          1.000000      0.396059          0.404520      0.566947   \n",
       "Gene Seymour       0.396059      1.000000          0.204598      0.314970   \n",
       "Michael Phillips   0.404520      0.204598          1.000000      1.000000   \n",
       "Claudia Puig       0.566947      0.314970          1.000000      1.000000   \n",
       "Mick LaSalle       0.594089      0.411765         -0.258199      0.566947   \n",
       "Jack Matthews      0.747018      0.963796          0.134840      0.028571   \n",
       "Toby               0.991241      0.381246         -1.000000      0.893405   \n",
       "\n",
       "                  Mick LaSalle  Jack Matthews      Toby  \n",
       "Lisa Rose             0.594089       0.747018  0.991241  \n",
       "Gene Seymour          0.411765       0.963796  0.381246  \n",
       "Michael Phillips     -0.258199       0.134840 -1.000000  \n",
       "Claudia Puig          0.566947       0.028571  0.893405  \n",
       "Mick LaSalle          1.000000       0.211289  0.924473  \n",
       "Jack Matthews         0.211289       1.000000  0.662849  \n",
       "Toby                  0.924473       0.662849  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lisa Rose': {'Lisa Rose': 1.0,\n",
       "  'Gene Seymour': 0.39605901719066977,\n",
       "  'Michael Phillips': 0.40451991747794525,\n",
       "  'Claudia Puig': 0.5669467095138409,\n",
       "  'Mick LaSalle': 0.5940885257860046,\n",
       "  'Jack Matthews': 0.747017880833996,\n",
       "  'Toby': 0.9912407071619304},\n",
       " 'Gene Seymour': {'Lisa Rose': 0.39605901719066977,\n",
       "  'Gene Seymour': 1.0,\n",
       "  'Michael Phillips': 0.20459830184114206,\n",
       "  'Claudia Puig': 0.314970394174356,\n",
       "  'Mick LaSalle': 0.4117647058823529,\n",
       "  'Jack Matthews': 0.9637956818756329,\n",
       "  'Toby': 0.3812464258315117},\n",
       " 'Michael Phillips': {'Lisa Rose': 0.40451991747794525,\n",
       "  'Gene Seymour': 0.20459830184114206,\n",
       "  'Michael Phillips': 1.0,\n",
       "  'Claudia Puig': 1.0,\n",
       "  'Mick LaSalle': -0.2581988897471611,\n",
       "  'Jack Matthews': 0.13483997249264842,\n",
       "  'Toby': -1.0},\n",
       " 'Claudia Puig': {'Lisa Rose': 0.5669467095138409,\n",
       "  'Gene Seymour': 0.314970394174356,\n",
       "  'Michael Phillips': 1.0,\n",
       "  'Claudia Puig': 1.0,\n",
       "  'Mick LaSalle': 0.5669467095138409,\n",
       "  'Jack Matthews': 0.02857142857142857,\n",
       "  'Toby': 0.8934051474415644},\n",
       " 'Mick LaSalle': {'Lisa Rose': 0.5940885257860046,\n",
       "  'Gene Seymour': 0.4117647058823529,\n",
       "  'Michael Phillips': -0.2581988897471611,\n",
       "  'Claudia Puig': 0.5669467095138409,\n",
       "  'Mick LaSalle': 1.0,\n",
       "  'Jack Matthews': 0.21128856368212914,\n",
       "  'Toby': 0.924473451641905},\n",
       " 'Jack Matthews': {'Lisa Rose': 0.747017880833996,\n",
       "  'Gene Seymour': 0.9637956818756329,\n",
       "  'Michael Phillips': 0.13483997249264842,\n",
       "  'Claudia Puig': 0.02857142857142857,\n",
       "  'Mick LaSalle': 0.21128856368212914,\n",
       "  'Jack Matthews': 1.0,\n",
       "  'Toby': 0.6628489803598702},\n",
       " 'Toby': {'Lisa Rose': 0.9912407071619304,\n",
       "  'Gene Seymour': 0.3812464258315117,\n",
       "  'Michael Phillips': -1.0,\n",
       "  'Claudia Puig': 0.8934051474415644,\n",
       "  'Mick LaSalle': 0.924473451641905,\n",
       "  'Jack Matthews': 0.6628489803598702,\n",
       "  'Toby': 1.0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就有了用户之间的相似度矩阵,我们可以看到比如Lisa Rose和Jack Matthews品味相近,这样的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算推荐\n",
    "\n",
    "在有了这张相似度表后,当我们要为某一个人推荐时,只要找到其他人和他的相关度,以其做为权重,为每个物品计算加权后的评分和即可.我们注意到有空值在rela_matrix中,这样就无法计算了,因此我们把空值替换为0.之后求出出自己外的每个电影在每个人那边的加权分,然后将结果初一权重的和来归一化."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_cf_list(name):\n",
    "    weights = sim_matrix.to_dict()[name]\n",
    "    del weights[name]\n",
    "    rela_score = rela_matrix.fillna(0).drop(index=[name]).to_dict()\n",
    "    result = {}\n",
    "    for key,tab in rela_score.items():\n",
    "        temp = 0\n",
    "        for i,value in tab.items():\n",
    "            temp += value*weights[i]\n",
    "        result[key]=temp\n",
    "    return {key:i/sum(weights.values()) for key,i in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Just My Luck': 0.9414122954368538,\n",
       " 'Lady in the Water': 1.6818946142760218,\n",
       " 'Snakes on a Plane': 3.8944822017436005,\n",
       " 'Superman Returns': 4.093713604813386,\n",
       " 'The Night Listener': 2.535448310746034,\n",
       " 'You, Me and Dupree': 2.05346350337327}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_cf_list(\"Lisa Rose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剩下的也就是给这些物品按得分排个序了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Superman Returns', 4.093713604813386),\n",
       " ('Snakes on a Plane', 3.8944822017436005),\n",
       " ('The Night Listener', 2.535448310746034),\n",
       " ('You, Me and Dupree', 2.05346350337327),\n",
       " ('Lady in the Water', 1.6818946142760218),\n",
       " ('Just My Luck', 0.9414122954368538)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(recommend_cf_list(\"Lisa Rose\").items(),key=lambda x:x[-1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于物品的也是一样,支持角色反过来而已.如果我们的业务是用户买了一样商品,我们要向他推荐另一样商品,而且尤其当我们对这个用户并没有收集到足够信息时那么我们就可以使用基于物品的协同过滤.计算物品间的相似程度,然后推荐相似的物品给."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lisa Rose</th>\n",
       "      <th>Gene Seymour</th>\n",
       "      <th>Michael Phillips</th>\n",
       "      <th>Claudia Puig</th>\n",
       "      <th>Mick LaSalle</th>\n",
       "      <th>Jack Matthews</th>\n",
       "      <th>Toby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Just My Luck</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady in the Water</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snakes on a Plane</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superman Returns</th>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Night Listener</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You, Me and Dupree</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Lisa Rose  Gene Seymour  Michael Phillips  Claudia Puig  \\\n",
       "Just My Luck              3.0           1.5               NaN           3.0   \n",
       "Lady in the Water         2.5           3.0               2.5           NaN   \n",
       "Snakes on a Plane         3.5           3.5               3.0           3.5   \n",
       "Superman Returns          3.5           5.0               3.5           4.0   \n",
       "The Night Listener        3.0           3.0               4.0           4.5   \n",
       "You, Me and Dupree        2.5           3.5               NaN           2.5   \n",
       "\n",
       "                    Mick LaSalle  Jack Matthews  Toby  \n",
       "Just My Luck                 2.0            NaN   NaN  \n",
       "Lady in the Water            3.0            3.0   NaN  \n",
       "Snakes on a Plane            4.0            4.0   4.5  \n",
       "Superman Returns             3.0            5.0   4.0  \n",
       "The Night Listener           3.0            3.0   NaN  \n",
       "You, Me and Dupree           2.0            3.5   1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rela_matrix_item = rela_matrix.T\n",
    "rela_matrix_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Just My Luck</th>\n",
       "      <th>Lady in the Water</th>\n",
       "      <th>Snakes on a Plane</th>\n",
       "      <th>Superman Returns</th>\n",
       "      <th>The Night Listener</th>\n",
       "      <th>You, Me and Dupree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Just My Luck</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.944911</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.422890</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-0.485662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady in the Water</th>\n",
       "      <td>-0.944911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>-0.612372</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snakes on a Plane</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>-0.566352</td>\n",
       "      <td>-0.645497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superman Returns</th>\n",
       "      <td>-0.422890</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.179847</td>\n",
       "      <td>0.657952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Night Listener</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>-0.612372</td>\n",
       "      <td>-0.566352</td>\n",
       "      <td>-0.179847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You, Me and Dupree</th>\n",
       "      <td>-0.485662</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.645497</td>\n",
       "      <td>0.657952</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Just My Luck  Lady in the Water  Snakes on a Plane  \\\n",
       "Just My Luck            1.000000          -0.944911          -0.333333   \n",
       "Lady in the Water      -0.944911           1.000000           0.763763   \n",
       "Snakes on a Plane      -0.333333           0.763763           1.000000   \n",
       "Superman Returns       -0.422890           0.487950           0.111803   \n",
       "The Night Listener      0.555556          -0.612372          -0.566352   \n",
       "You, Me and Dupree     -0.485662           0.333333          -0.645497   \n",
       "\n",
       "                    Superman Returns  The Night Listener  You, Me and Dupree  \n",
       "Just My Luck               -0.422890            0.555556           -0.485662  \n",
       "Lady in the Water           0.487950           -0.612372            0.333333  \n",
       "Snakes on a Plane           0.111803           -0.566352           -0.645497  \n",
       "Superman Returns            1.000000           -0.179847            0.657952  \n",
       "The Night Listener         -0.179847            1.000000           -0.250000  \n",
       "You, Me and Dupree          0.657952           -0.250000            1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix_item = rela_matrix_item.T.corr()\n",
    "sim_matrix_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_cf_item(item):\n",
    "    result = sim_matrix_item.drop(index=[item])[item]\n",
    "    return result.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Night Listener    0.555556\n",
       "Snakes on a Plane    -0.333333\n",
       "Superman Returns     -0.422890\n",
       "You, Me and Dupree   -0.485662\n",
       "Lady in the Water    -0.944911\n",
       "Name: Just My Luck, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_cf_item(\"Just My Luck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至我们还可以主动选择推送一个新产品给什么人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_cf_item_to_people(name):\n",
    "    weights = sim_matrix_item.to_dict()[name]\n",
    "    del weights[name]\n",
    "    rela_score = rela_matrix_item.fillna(0).drop(index=[name]).to_dict()\n",
    "    result = {}\n",
    "    for key,tab in rela_score.items():\n",
    "        temp = 0\n",
    "        for i,value in tab.items():\n",
    "            temp += value*weights[i]\n",
    "        result[key]=temp\n",
    "    return sorted({key:i/sum(weights.values()) for key,i in result.items()}.items(),key=lambda x:x[-1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Claudia Puig', 7.0415123776298385),\n",
       " ('Lisa Rose', 3.0048251432487247),\n",
       " ('Gene Seymour', 2.4013616874633836),\n",
       " ('Jack Matthews', 1.6546658058621195),\n",
       " ('Mick LaSalle', 1.5382225075580365),\n",
       " ('Toby', 0.29611513812929585),\n",
       " ('Michael Phillips', -0.052731633004085426)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_cf_item_to_people(\"Snakes on a Plane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 协同过滤的优缺点\n",
    "\n",
    "协同过滤是最基本的推荐算法,它的优点\n",
    "+ 大部分计算可以离线运算\n",
    "+ 可解释性很好\n",
    "\n",
    "但缺点也很明显:\n",
    "+ 对比较新的数据难以处理(稀疏性问题)\n",
    "+ 必须要有用户-物品关系数据(冷启动问题)\n",
    "+ 计算量巨大\n",
    "\n",
    "针对这些问题还有一些改进算法,比如计算相似度可以通过标签等外部信息做聚类,然后将聚类的结果作为用户群进行推荐,当某用户属于这个用户群,这样问题就成了向某个群体推荐商品,这样可以大大降低计算量\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于矩阵分解的算法\n",
    "\n",
    "这一类算法往往利用到矩阵分解,它基于这么一个假设,用户喜欢某个东西不是喜欢它本身,而是喜欢其一些特征,比如喜欢集体智慧编程的可能也会喜欢数学之美,因为他们都是介绍算法的书.当然在关系矩阵中我们没办法或得到不同物品的特征,所以我们就假设有这么一些特征我们也不知道是什么,它就是决定用户偏好的因子.这种算法统称为隐因子模型(LFM)\n",
    "\n",
    "$$ R_{M,N}=P_{M,F}⋅Q_{F,N} $$\n",
    "\n",
    "其中$F$代表隐因子的数量(超参);$R_{M,N}$为我们的特征矩阵,这个矩阵通常是一个非常稀疏的矩阵.$P_{M,F}$为用户对各隐因子的喜好程度矩阵,Q_{F,N}则代表隐因子在物品上的概率分布.\n",
    "\n",
    "而我们训练的目标是使得对所有的$r_{m,n}≠0$,且$r_{m,n}$和$\\hat{r}_{m,n}$尽可能接近，即\n",
    "\n",
    "$$ min: Loss ==\\sum\\limits_{r_{m,n}\\neq0}(r_{m,n} -\\hat{r}_{m,n})^2$$\n",
    "\n",
    "为防止过拟合,加个正则项,以防止$P_{m,f}$,$Q_{f,n}$过大或过小,即:\n",
    "\n",
    "$$ min: Loss ==\\sum\\limits_{r_{m,n}\\neq0}(r_{m,n} -\\hat{r}_{m,n})^2 + \\lambda(\\sum P_{m,f}^2+\\sum Q_{f,n})$$\n",
    "\n",
    "这样我们就可以用梯度下降法来训练模型了.\n",
    "\n",
    "我们使用的是keras2来构造模型.使用movielens的数据集以模拟真实情况下数据稀疏的情况."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, Dense, Reshape\n",
    "from keras.layers.merge import Dot, Concatenate\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./data/ratings.dat', sep = '::', engine='python',names = ['user_id','movie_id','rating','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291\n",
       "5        1      1197       3  978302268\n",
       "6        1      1287       5  978302039\n",
       "7        1      2804       5  978300719\n",
       "8        1       594       4  978302268\n",
       "9        1       919       4  978301368"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的数据集是一个用户id和电影id构成的关系表,rating是评分.,首先我们来观察下数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.max(ratings['user_id'])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = np.max(ratings['movie_id'])\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ratings['rating'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.581564453029317\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ratings['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huangsizhe/Lib/conda/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "k = 128 # 隐因子数\n",
    "# 用户嵌入\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(M + 1, k, input_length = 1))\n",
    "model1.add(Reshape((k,)))\n",
    "\n",
    "# 物品嵌入\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(N + 1, k, input_length = 1))\n",
    "model2.add(Reshape((k,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的思路是通过计算用户和内容的向量乘积得出评分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "m = Dot(axes=1)([model1.output, model2.output])\n",
    "model_output = m\n",
    "model = Model([model1.input, model2.input], model_output)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings['user_id'].values\n",
    "movies = ratings['movie_id'].values\n",
    "X_train = [users, movies]\n",
    "y_train = ratings['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huangsizhe/Lib/conda/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1000209/1000209 [==============================] - 44s 44us/step - loss: 4.2632\n",
      "Epoch 2/50\n",
      "1000209/1000209 [==============================] - 44s 44us/step - loss: 0.8199\n",
      "Epoch 3/50\n",
      "1000209/1000209 [==============================] - 44s 44us/step - loss: 0.7405\n",
      "Epoch 4/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.6754\n",
      "Epoch 5/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.6114\n",
      "Epoch 6/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.5421\n",
      "Epoch 7/50\n",
      "1000209/1000209 [==============================] - 45s 45us/step - loss: 0.4710\n",
      "Epoch 8/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.4051\n",
      "Epoch 9/50\n",
      "1000209/1000209 [==============================] - 43s 43us/step - loss: 0.3495\n",
      "Epoch 10/50\n",
      "1000209/1000209 [==============================] - 38s 38us/step - loss: 0.3053\n",
      "Epoch 11/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.2715\n",
      "Epoch 12/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.2456\n",
      "Epoch 13/50\n",
      "1000209/1000209 [==============================] - 45s 45us/step - loss: 0.2255\n",
      "Epoch 14/50\n",
      "1000209/1000209 [==============================] - 44s 44us/step - loss: 0.2096\n",
      "Epoch 15/50\n",
      "1000209/1000209 [==============================] - 44s 44us/step - loss: 0.1972\n",
      "Epoch 16/50\n",
      "1000209/1000209 [==============================] - 43s 43us/step - loss: 0.1865\n",
      "Epoch 17/50\n",
      "1000209/1000209 [==============================] - 44s 44us/step - loss: 0.1779\n",
      "Epoch 18/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1706\n",
      "Epoch 19/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.1642\n",
      "Epoch 20/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1586\n",
      "Epoch 21/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1537\n",
      "Epoch 22/50\n",
      "1000209/1000209 [==============================] - 43s 43us/step - loss: 0.1495\n",
      "Epoch 23/50\n",
      "1000209/1000209 [==============================] - 45s 45us/step - loss: 0.1457\n",
      "Epoch 24/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.1422\n",
      "Epoch 25/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1390\n",
      "Epoch 26/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1363\n",
      "Epoch 27/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1337\n",
      "Epoch 28/50\n",
      "1000209/1000209 [==============================] - 43s 43us/step - loss: 0.1314\n",
      "Epoch 29/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1293\n",
      "Epoch 30/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1273\n",
      "Epoch 31/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1255\n",
      "Epoch 32/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.1239\n",
      "Epoch 33/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1222\n",
      "Epoch 34/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1207\n",
      "Epoch 35/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.1195\n",
      "Epoch 36/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1181\n",
      "Epoch 37/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.1168\n",
      "Epoch 38/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1158\n",
      "Epoch 39/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1147\n",
      "Epoch 40/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1137\n",
      "Epoch 41/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1128\n",
      "Epoch 42/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1119\n",
      "Epoch 43/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1109\n",
      "Epoch 44/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1102\n",
      "Epoch 45/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1094\n",
      "Epoch 46/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1087\n",
      "Epoch 47/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.1080\n",
      "Epoch 48/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1074\n",
      "Epoch 49/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.1067\n",
      "Epoch 50/50\n",
      "1000209/1000209 [==============================] - 42s 42us/step - loss: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2fedf1d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 500, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看下模型预测效果,注意我们这里作为演示,只做了模型拟合程度,读者可以把原始数据集分成训练,验证和测试数据集,评估模型准确率和泛化能力.我们这里看一个例子--预测第10号用户对第99号内容的打分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.965229]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=10\n",
    "j=99\n",
    "pred = model.predict([np.array([users[i]]), np.array([movies[j]])])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度模型\n",
    "\n",
    "在一般矩阵分解模型的基础上,我们可以结合深度神经网络替代简单的矩阵乘法,以此来挖掘更深层次的关联信息.在代码上我们只需要修改Dot为连接,然后构造多层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128\n",
    "# 输入\n",
    "input_1 = Input(shape=(1,))\n",
    "model1 = Embedding(M + 1, k, input_length = 1)(input_1)\n",
    "model1 = Reshape((k,))(model1)\n",
    "input_2 = Input(shape=(1,))\n",
    "model2 = Embedding(N + 1, k, input_length = 1)(input_2)\n",
    "model2 = Reshape((k,))(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huangsizhe/Lib/conda/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# 模型融合\n",
    "model = Concatenate()([model1, model2])\n",
    "# 神经网络构造\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(k, activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(int(k/4), activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(int(k/16), activation = 'relu')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "# 输出\n",
    "yhat = Dense(1, activation = 'linear')(model)\n",
    "model = Model([input_1, input_2], yhat)\n",
    "model.compile(loss = 'mse', optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 3.2110\n",
      "Epoch 2/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 1.9703\n",
      "Epoch 3/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 1.4733\n",
      "Epoch 4/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 1.1621\n",
      "Epoch 5/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.9970\n",
      "Epoch 6/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.9420\n",
      "Epoch 7/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.9269\n",
      "Epoch 8/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.9174\n",
      "Epoch 9/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.9099\n",
      "Epoch 10/50\n",
      "1000209/1000209 [==============================] - 38s 38us/step - loss: 0.8968\n",
      "Epoch 11/50\n",
      "1000209/1000209 [==============================] - 39s 39us/step - loss: 0.8917\n",
      "Epoch 12/50\n",
      "1000209/1000209 [==============================] - 38s 38us/step - loss: 0.8879\n",
      "Epoch 13/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.8844\n",
      "Epoch 14/50\n",
      "1000209/1000209 [==============================] - 38s 38us/step - loss: 0.8810\n",
      "Epoch 15/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8782\n",
      "Epoch 16/50\n",
      "1000209/1000209 [==============================] - 41s 41us/step - loss: 0.8755\n",
      "Epoch 17/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8721\n",
      "Epoch 18/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8696\n",
      "Epoch 19/50\n",
      "1000209/1000209 [==============================] - 33s 33us/step - loss: 0.8675\n",
      "Epoch 20/50\n",
      "1000209/1000209 [==============================] - 33s 33us/step - loss: 0.8649\n",
      "Epoch 21/50\n",
      "1000209/1000209 [==============================] - 33s 33us/step - loss: 0.8617\n",
      "Epoch 22/50\n",
      "1000209/1000209 [==============================] - 34s 34us/step - loss: 0.8580\n",
      "Epoch 23/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8564\n",
      "Epoch 24/50\n",
      "1000209/1000209 [==============================] - 33s 33us/step - loss: 0.8546\n",
      "Epoch 25/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.8517\n",
      "Epoch 26/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.8507\n",
      "Epoch 27/50\n",
      "1000209/1000209 [==============================] - 40s 40us/step - loss: 0.8486\n",
      "Epoch 28/50\n",
      "1000209/1000209 [==============================] - 32s 32us/step - loss: 0.8468\n",
      "Epoch 29/50\n",
      "1000209/1000209 [==============================] - 32s 32us/step - loss: 0.8452\n",
      "Epoch 30/50\n",
      "1000209/1000209 [==============================] - 38s 38us/step - loss: 0.8428\n",
      "Epoch 31/50\n",
      "1000209/1000209 [==============================] - 39s 39us/step - loss: 0.8423\n",
      "Epoch 32/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8417\n",
      "Epoch 33/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8393\n",
      "Epoch 34/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.8378\n",
      "Epoch 35/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.8361\n",
      "Epoch 36/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8362\n",
      "Epoch 37/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8339\n",
      "Epoch 38/50\n",
      "1000209/1000209 [==============================] - 33s 33us/step - loss: 0.8335\n",
      "Epoch 39/50\n",
      "1000209/1000209 [==============================] - 32s 32us/step - loss: 0.8324\n",
      "Epoch 40/50\n",
      "1000209/1000209 [==============================] - 34s 34us/step - loss: 0.8322\n",
      "Epoch 41/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8297\n",
      "Epoch 42/50\n",
      "1000209/1000209 [==============================] - 38s 38us/step - loss: 0.8282\n",
      "Epoch 43/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8293\n",
      "Epoch 44/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.8277\n",
      "Epoch 45/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8269\n",
      "Epoch 46/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8265\n",
      "Epoch 47/50\n",
      "1000209/1000209 [==============================] - 37s 37us/step - loss: 0.8245\n",
      "Epoch 48/50\n",
      "1000209/1000209 [==============================] - 36s 36us/step - loss: 0.8236\n",
      "Epoch 49/50\n",
      "1000209/1000209 [==============================] - 34s 34us/step - loss: 0.8229\n",
      "Epoch 50/50\n",
      "1000209/1000209 [==============================] - 35s 35us/step - loss: 0.8215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2673fe10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 1000, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.392807]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=10\n",
    "j=99\n",
    "pred = model.predict([np.array([users[i]]), np.array([movies[j]])])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于矩阵分解的算法优势和局限性\n",
    "\n",
    "矩阵分解的算法相比协同过滤更加复杂,但它带来了一个优势--可以更好的处理稀疏矩阵.然而这依然脱离不了用已有的关联做推荐固有的局限性--无法利用外部信息.\n",
    "\n",
    "要利用外部的特征,从深度模型改造,可以使用深宽模型,这个会在最后一节介绍"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
